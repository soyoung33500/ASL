{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie5uLDH4uzAp",
        "outputId": "4c98e6d1-5f10-46b2-a4fc-4cd4df704dce"
      },
      "source": [
        "# yolov5 git 다운로드\n",
        "!git clone https://github.com/ultralytics/yolov5 \n",
        "%cd yolov5\n",
        "!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14424, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 14424 (delta 15), reused 25 (delta 9), pack-reused 14379\u001b[K\n",
            "Receiving objects: 100% (14424/14424), 13.41 MiB | 9.51 MiB/s, done.\n",
            "Resolving deltas: 100% (9965/9965), done.\n",
            "/content/yolov5\n",
            "HEAD is now at fbe67e4 Fix `OMP_NUM_THREADS=1` for macOS (#8624)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "#,패키지, 유틸, 모델, 기본가중치 다운로드\n",
        "!pip install -qr requirements.txt  \n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output \n",
        "from utils.downloads import attempt_download "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug_PhK1oqwQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8aeda8b0-774e-4445-ed85-cb2743518093"
      },
      "source": [
        "#roboflow 에서 데이터셋 다운로드\n",
        "%cd /content/yolov5\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"IdkSkVujyej85JtjOtfq\")\n",
        "project = rf.workspace(\"tfod-p4luj\").project(\"sign_language-acf74\")\n",
        "dataset = project.version(2).download(\"yolov5\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.17.tar.gz (25 kB)\n",
            "Collecting certifi==2021.5.30\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 45.7 MB/s \n",
            "\u001b[?25hCollecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 63.9 MB/s \n",
            "\u001b[?25hCollecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (7.1.2)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.23.0)\n",
            "Collecting requests_toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.15.0)\n",
            "Collecting urllib3==1.26.6\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.64.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (6.0)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.3.1->roboflow) (4.1.1)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->roboflow) (2.1.1)\n",
            "Building wheels for collected packages: roboflow, wget\n",
            "  Building wheel for roboflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for roboflow: filename=roboflow-0.2.17-py3-none-any.whl size=31935 sha256=e468f46bd664b9d10e46e27b195da6e1f97db467887dbc13445b1f37d6ebb7a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/38/3c/b4ac4d8a9d9b44bdcd51f6148ec810b0f05a404e5fed8df48d\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=39f55ce3bf8348cd995d635bfbf06534892167aa0ef5f684b3b2f49b5c8e766b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built roboflow wget\n",
            "Installing collected packages: urllib3, certifi, requests, pyparsing, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.1 roboflow-0.2.17 urllib3-1.26.6 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cycler",
                  "pyparsing",
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Sign_language-2 to yolov5pytorch: 100% [67562449 / 67562449] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Sign_language-2 in yolov5pytorch:: 100%|██████████| 10254/10254 [00:02<00:00, 3916.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d96073f-e81b-474d-c6c9-cfe5ff10a65f"
      },
      "source": [
        "#학습시키기\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 32 --epochs 1000 --data {dataset.location}/data.yaml \\\n",
        "--cfg ./models/yolov5s.yaml --weights ' ' --name yolov5s_results  --cache "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights= , cfg=./models/yolov5s.yaml, data=/content/yolov5/Sign_language-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1000, batch_size=32, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 307 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 148MB/s]\n",
            "Overriding model.yaml nc=80 with nc=26\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     83607  models.yolo.Detect                      [26, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 270 layers, 7089751 parameters, 7089751 gradients, 16.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/Sign_language-2/train/labels' images and labels...4984 found, 0 missing, 0 empty, 0 corrupt: 100% 4984/4984 [00:02<00:00, 2044.78it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/Sign_language-2/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.6GB ram): 100% 4984/4984 [00:10<00:00, 473.75it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Sign_language-2/valid/labels' images and labels...83 found, 0 missing, 0 empty, 0 corrupt: 100% 83/83 [00:00<00:00, 666.32it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/Sign_language-2/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 83/83 [00:00<00:00, 162.98it/s]\n",
            "Plotting labels to runs/train/yolov5s_results/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.45 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5s_results\u001b[0m\n",
            "Starting training for 1000 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     0/999     3.16G   0.09457   0.02254   0.08277        98       416:  21% 33/156 [00:12<00:38,  3.19it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJFbEPx3etOk",
        "outputId": "d4fc8693-f7c5-43dc-e37a-124714d5585c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과 폴더를 압축해서 구글 드라이브에 저장\n",
        "!zip -r /content/drive/MyDrive/result.zip /content/yolov5/runs/train/yolov5s_results/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfj9R_0bJqU9",
        "outputId": "d112ea49-f5c8-4210-d381-646ea67d6bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/yolov5/runs/train/yolov5s_results/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/weights/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/weights/best.pt (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/weights/last.pt (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/R_curve.png (deflated 11%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/PR_curve.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/val_batch2_pred.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/events.out.tfevents.1666505440.7bcadb40cced.486.0 (deflated 23%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/val_batch1_labels.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/F1_curve.png (deflated 9%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/labels.jpg (deflated 29%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/val_batch2_labels.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/val_batch1_pred.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/confusion_matrix.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/val_batch0_labels.jpg (deflated 6%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/val_batch0_pred.jpg (deflated 6%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/opt.yaml (deflated 43%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/train_batch1.jpg (deflated 4%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/results.csv (deflated 83%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/train_batch2.jpg (deflated 3%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/hyp.yaml (deflated 45%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/train_batch0.jpg (deflated 4%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/results.png (deflated 6%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/P_curve.png (deflated 11%)\n",
            "  adding: content/yolov5/runs/train/yolov5s_results/labels_correlogram.jpg (deflated 32%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nmZZnWOgJ2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e299447a-2b91-4608-9bfe-7cf05267e200"
      },
      "source": [
        "#학습된 가중치로 test이미지 탐색\n",
        "%cd /content/yolov5/\n",
        "!python detect.py --weights ./runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source ./Sign_language-2/test/images/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./runs/train/yolov5s_results2/weights/best.pt'], source=./Sign_language-2/test/images/, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7080247 parameters, 0 gradients, 16.0 GFLOPs\n",
            "image 1/54 /content/yolov5/Sign_language-2/test/images/hand5_a_dif_seg_4_cropped_jpeg.rf.1e992e3afddcaefe90993d108fac1a73.jpg: 416x416 Done. (0.008s)\n",
            "image 2/54 /content/yolov5/Sign_language-2/test/images/hand5_a_dif_seg_5_cropped_jpeg.rf.0d810949fbd71b760fa711883b8df7c8.jpg: 416x416 Done. (0.008s)\n",
            "image 3/54 /content/yolov5/Sign_language-2/test/images/hand5_b_dif_seg_4_cropped_jpeg.rf.80d4353a205a0631f9ca5a08db5b3cc5.jpg: 416x416 Done. (0.008s)\n",
            "image 4/54 /content/yolov5/Sign_language-2/test/images/hand5_b_dif_seg_5_cropped_jpeg.rf.8926e2214c64a13ca6042dea948d4449.jpg: 416x416 Done. (0.008s)\n",
            "image 5/54 /content/yolov5/Sign_language-2/test/images/hand5_c_dif_seg_4_cropped_jpeg.rf.8d49f86ec0666d60003a1f13f04bf40b.jpg: 416x416 Done. (0.008s)\n",
            "image 6/54 /content/yolov5/Sign_language-2/test/images/hand5_c_dif_seg_5_cropped_jpeg.rf.5e5fe5ff09011197112386d793ac3651.jpg: 416x416 Done. (0.009s)\n",
            "image 7/54 /content/yolov5/Sign_language-2/test/images/hand5_d_dif_seg_4_cropped_jpeg.rf.2daeb6c2a80e70f96aaf73104b130c98.jpg: 416x416 Done. (0.008s)\n",
            "image 8/54 /content/yolov5/Sign_language-2/test/images/hand5_d_dif_seg_5_cropped_jpeg.rf.cd17f38645cefe309f46b53ade131ea1.jpg: 416x416 Done. (0.008s)\n",
            "image 9/54 /content/yolov5/Sign_language-2/test/images/hand5_e_dif_seg_4_cropped_jpeg.rf.630a5fcc2dabb6d7e963b9977f16e188.jpg: 416x416 Done. (0.008s)\n",
            "image 10/54 /content/yolov5/Sign_language-2/test/images/hand5_e_dif_seg_5_cropped_jpeg.rf.53a3f57d66630b378acd04fb6de4e7d5.jpg: 416x416 Done. (0.008s)\n",
            "image 11/54 /content/yolov5/Sign_language-2/test/images/hand5_f_dif_seg_4_cropped_jpeg.rf.829bed80adb13a3b9da0eb29dd65280c.jpg: 416x416 Done. (0.008s)\n",
            "image 12/54 /content/yolov5/Sign_language-2/test/images/hand5_f_dif_seg_5_cropped_jpeg.rf.590fdab1a06b345d61b99813995098c3.jpg: 416x416 Done. (0.009s)\n",
            "image 13/54 /content/yolov5/Sign_language-2/test/images/hand5_g_dif_seg_4_cropped_jpeg.rf.46accd0f83a557f9532a91cb4b3e31fd.jpg: 416x416 Done. (0.008s)\n",
            "image 14/54 /content/yolov5/Sign_language-2/test/images/hand5_g_dif_seg_5_cropped_jpeg.rf.0f5c54de487fc4faddbf85d0ac273129.jpg: 416x416 Done. (0.008s)\n",
            "image 15/54 /content/yolov5/Sign_language-2/test/images/hand5_h_dif_seg_4_cropped_jpeg.rf.020be4316457c60a6a0fffb03b2de241.jpg: 416x416 Done. (0.008s)\n",
            "image 16/54 /content/yolov5/Sign_language-2/test/images/hand5_h_dif_seg_5_cropped_jpeg.rf.5bccb6ce6cef123e89e292aa6b3a54fd.jpg: 416x416 Done. (0.008s)\n",
            "image 17/54 /content/yolov5/Sign_language-2/test/images/hand5_i_dif_seg_4_cropped_jpeg.rf.9a1f4f2670fe69f6763630221e5dfad5.jpg: 416x416 Done. (0.008s)\n",
            "image 18/54 /content/yolov5/Sign_language-2/test/images/hand5_i_dif_seg_5_cropped_jpeg.rf.baafae12183026ff20d07160b5e8f38d.jpg: 416x416 Done. (0.010s)\n",
            "image 19/54 /content/yolov5/Sign_language-2/test/images/hand5_j_dif_seg_4_cropped_jpeg.rf.f67b944f74131557b10444674177272f.jpg: 416x416 Done. (0.008s)\n",
            "image 20/54 /content/yolov5/Sign_language-2/test/images/hand5_j_dif_seg_5_cropped_jpeg.rf.cb11b65159baf761046dde7a2f402246.jpg: 416x416 Done. (0.008s)\n",
            "image 21/54 /content/yolov5/Sign_language-2/test/images/hand5_k_dif_seg_4_cropped_jpeg.rf.6d6d728a28b5962cfca2195fabe15200.jpg: 416x416 Done. (0.009s)\n",
            "image 22/54 /content/yolov5/Sign_language-2/test/images/hand5_k_dif_seg_5_cropped_jpeg.rf.c4fe719cb8cc44aa83b3c59fd282b196.jpg: 416x416 Done. (0.008s)\n",
            "image 23/54 /content/yolov5/Sign_language-2/test/images/hand5_l_dif_seg_4_cropped_jpeg.rf.a83421e929218531fcd5bfc92981f360.jpg: 416x416 Done. (0.008s)\n",
            "image 24/54 /content/yolov5/Sign_language-2/test/images/hand5_l_dif_seg_5_cropped_jpeg.rf.1027831a2d38bbdbcd139fc13dc7db55.jpg: 416x416 Done. (0.009s)\n",
            "image 25/54 /content/yolov5/Sign_language-2/test/images/hand5_m_dif_seg_4_cropped_jpeg.rf.cf7422d8d07cf317ad50b65b16cec298.jpg: 416x416 Done. (0.009s)\n",
            "image 26/54 /content/yolov5/Sign_language-2/test/images/hand5_m_dif_seg_5_cropped_jpeg.rf.526202b790d61877df2c1df53907cdd6.jpg: 416x416 Done. (0.008s)\n",
            "image 27/54 /content/yolov5/Sign_language-2/test/images/hand5_n_dif_seg_4_cropped_jpeg.rf.13ff49eefcff39c08c14200fdd8365a9.jpg: 416x416 Done. (0.009s)\n",
            "image 28/54 /content/yolov5/Sign_language-2/test/images/hand5_n_dif_seg_5_cropped_jpeg.rf.4637815ed25fada4ea8482b577953d9e.jpg: 416x416 Done. (0.009s)\n",
            "image 29/54 /content/yolov5/Sign_language-2/test/images/hand5_o_dif_seg_4_cropped_jpeg.rf.d012eec868e4f032d3dccac279b2b628.jpg: 416x416 Done. (0.009s)\n",
            "image 30/54 /content/yolov5/Sign_language-2/test/images/hand5_o_dif_seg_5_cropped_jpeg.rf.a3c356e8f191e9eea9fe5bb0cff547e8.jpg: 416x416 Done. (0.008s)\n",
            "image 31/54 /content/yolov5/Sign_language-2/test/images/hand5_p_bot_seg_4_cropped_jpeg.rf.33513b9f7d6bd75bc95218f6789eb6b1.jpg: 416x416 Done. (0.009s)\n",
            "image 32/54 /content/yolov5/Sign_language-2/test/images/hand5_p_dif_seg_1_cropped_jpeg.rf.7a68d0ed0ea9913c960a82ca31530adb.jpg: 416x416 Done. (0.008s)\n",
            "image 33/54 /content/yolov5/Sign_language-2/test/images/hand5_p_dif_seg_4_cropped_jpeg.rf.a4d964e102e0c1e855ac3701fd735e52.jpg: 416x416 Done. (0.008s)\n",
            "image 34/54 /content/yolov5/Sign_language-2/test/images/hand5_p_dif_seg_5_cropped_jpeg.rf.49f9fee0d97a192850e784a3d93637e2.jpg: 416x416 Done. (0.008s)\n",
            "image 35/54 /content/yolov5/Sign_language-2/test/images/hand5_q_dif_seg_4_cropped_jpeg.rf.816118035186abd96d31641772b0663d.jpg: 416x416 Done. (0.008s)\n",
            "image 36/54 /content/yolov5/Sign_language-2/test/images/hand5_q_dif_seg_5_cropped_jpeg.rf.5caff36f0037f6eb537af87a0746e59a.jpg: 416x416 Done. (0.008s)\n",
            "image 37/54 /content/yolov5/Sign_language-2/test/images/hand5_r_dif_seg_4_cropped_jpeg.rf.ddd5cc08e441b07bd28aaa850378985b.jpg: 416x416 Done. (0.008s)\n",
            "image 38/54 /content/yolov5/Sign_language-2/test/images/hand5_r_dif_seg_5_cropped_jpeg.rf.b3844701f797bb9c50b8a18af1bae8ba.jpg: 416x416 Done. (0.010s)\n",
            "image 39/54 /content/yolov5/Sign_language-2/test/images/hand5_s_dif_seg_4_cropped_jpeg.rf.c8d3177a7532bd3b96414cd49c3f9513.jpg: 416x416 Done. (0.008s)\n",
            "image 40/54 /content/yolov5/Sign_language-2/test/images/hand5_s_dif_seg_5_cropped_jpeg.rf.7c9414b532f815825cdf1c4bb82f0758.jpg: 416x416 Done. (0.008s)\n",
            "image 41/54 /content/yolov5/Sign_language-2/test/images/hand5_t_dif_seg_4_cropped_jpeg.rf.2395a54dac0f63d01046ddca4aec0604.jpg: 416x416 Done. (0.008s)\n",
            "image 42/54 /content/yolov5/Sign_language-2/test/images/hand5_t_dif_seg_5_cropped_jpeg.rf.9d15a1e1ccc446ae5423f27b76a0be42.jpg: 416x416 Done. (0.009s)\n",
            "image 43/54 /content/yolov5/Sign_language-2/test/images/hand5_u_dif_seg_4_cropped_jpeg.rf.1945fa52ee32852f1aae2b26ee23db93.jpg: 416x416 Done. (0.008s)\n",
            "image 44/54 /content/yolov5/Sign_language-2/test/images/hand5_u_dif_seg_5_cropped_jpeg.rf.750489d209f9e0d50de42f890d6e4261.jpg: 416x416 Done. (0.008s)\n",
            "image 45/54 /content/yolov5/Sign_language-2/test/images/hand5_v_dif_seg_4_cropped_jpeg.rf.54b6c1b3ec748ff8206746aec701dc6c.jpg: 416x416 Done. (0.009s)\n",
            "image 46/54 /content/yolov5/Sign_language-2/test/images/hand5_v_dif_seg_5_cropped_jpeg.rf.cf5c292231e7fd52c2d72513b12e8b2f.jpg: 416x416 Done. (0.008s)\n",
            "image 47/54 /content/yolov5/Sign_language-2/test/images/hand5_w_dif_seg_4_cropped_jpeg.rf.7c84ed2f3e2d85dc5258222edba7f7b8.jpg: 416x416 Done. (0.008s)\n",
            "image 48/54 /content/yolov5/Sign_language-2/test/images/hand5_w_dif_seg_5_cropped_jpeg.rf.566a0c66fc8bfdcb293788fe5313b24d.jpg: 416x416 Done. (0.008s)\n",
            "image 49/54 /content/yolov5/Sign_language-2/test/images/hand5_x_dif_seg_4_cropped_jpeg.rf.9d9348476ea0efd1eb655fb5cac91491.jpg: 416x416 Done. (0.008s)\n",
            "image 50/54 /content/yolov5/Sign_language-2/test/images/hand5_x_dif_seg_5_cropped_jpeg.rf.73fd638c2453f9900353e7fc70b218ea.jpg: 416x416 Done. (0.008s)\n",
            "image 51/54 /content/yolov5/Sign_language-2/test/images/hand5_y_dif_seg_4_cropped_jpeg.rf.bfbbaf0a287811b8446dacaf79f76e54.jpg: 416x416 Done. (0.008s)\n",
            "image 52/54 /content/yolov5/Sign_language-2/test/images/hand5_y_dif_seg_5_cropped_jpeg.rf.00ec4e239bff30741db80fcc7ed1fb3e.jpg: 416x416 Done. (0.008s)\n",
            "image 53/54 /content/yolov5/Sign_language-2/test/images/hand5_z_dif_seg_4_cropped_jpeg.rf.44cffdcccb525669dce82eaf41d09584.jpg: 416x416 Done. (0.008s)\n",
            "image 54/54 /content/yolov5/Sign_language-2/test/images/hand5_z_dif_seg_5_cropped_jpeg.rf.5b3c3fb795e4a5bcf7e92b7474cf644c.jpg: 416x416 Done. (0.009s)\n",
            "Speed: 0.3ms pre-process, 8.4ms inference, 0.4ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odKEqYtTgbRc"
      },
      "source": [
        "#이미지 탐색결과 exp폴더에 저장\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): \n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}